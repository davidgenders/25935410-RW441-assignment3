{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nn.models import OneHiddenMLP\n",
        "from nn.training import train_passive, TrainConfig\n",
        "from nn.evaluation import evaluate_classification\n",
        "from nn.experiments import ActiveConfig, run_active_classification\n",
        "from nn.strategies import uncertainty_sampling, sensitivity_sampling, UncertaintySamplingConfig\n",
        "from typing import Dict\n",
        "\n",
        "SAVE_DIR = os.path.join('..', 'report', 'figures')\n",
        "DATA_DIR = os.path.join('..', 'data')\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(DATA_DIR, 'cls_uncertainty_results.json'), 'r') as f:\n",
        "    unc_results = json.load(f)\n",
        "with open(os.path.join(DATA_DIR, 'cls_sensitivity_results.json'), 'r') as f:\n",
        "    sen_results = json.load(f)\n",
        "with open(os.path.join(DATA_DIR, 'passive_cls_best.json'), 'r') as f:\n",
        "    pas_results = json.load(f)\n",
        "\n",
        "DATASETS = ['iris', 'wine', 'breast_cancer']\n",
        "METRICS = ['accuracy', 'f1_macro']\n",
        "UNCERTAINTY_METHODS = ['entropy', 'margin', 'least_confidence']\n",
        "\n",
        "ACTIVE_PARAMS = {\n",
        "    'iris': {'init': 10, 'query': 5, 'budget': 80},\n",
        "    'wine': {'init': 10, 'query': 5, 'budget': 100},\n",
        "    'breast_cancer': {'init': 20, 'query': 10, 'budget': 200},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_splits(dataset: str):\n",
        "    # Load data\n",
        "    if dataset == \"iris\":\n",
        "        ds = datasets.load_iris()\n",
        "    elif dataset == \"wine\":\n",
        "        ds = datasets.load_wine()\n",
        "    elif dataset == \"breast_cancer\":\n",
        "        ds = datasets.load_breast_cancer()\n",
        "    \n",
        "    X, y = ds.data, ds.target\n",
        "\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    return X_train_val, X_test, y_train_val, y_test\n",
        "\n",
        "def evaluate_passive_test(dataset: str) -> Dict[str, float]:\n",
        "    # Get best hyperparameters from tuning results\n",
        "    best_cfg = pas_results[dataset]['best_cfg']\n",
        "    lr = best_cfg['lr']\n",
        "    wd = best_cfg['wd']\n",
        "    hidden = best_cfg['hidden']\n",
        "    bs = best_cfg['bs']\n",
        "    \n",
        "    # Get data splits\n",
        "    X_train_val, X_test, y_train_val, y_test = get_data_splits(dataset)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_val, dtype=torch.long)\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "    \n",
        "    # Train model\n",
        "    model = OneHiddenMLP(input_dim=X_train_scaled.shape[1], hidden_units=hidden, output_dim=len(np.unique(y_train_val)))\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    config = TrainConfig(learning_rate=lr, weight_decay=wd, batch_size=bs, max_epochs=200, patience=20)\n",
        "    \n",
        "    train_passive(model, train_loader, test_loader, loss_fn, config)\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    metrics = evaluate_classification(model, test_loader)\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "def evaluate_active_test(dataset: str, strategy: str, method: str, budget: int) -> Dict[str, float]:\n",
        "    dataset_params = ACTIVE_PARAMS[dataset]\n",
        "    init = dataset_params['init']\n",
        "    query = dataset_params['query']\n",
        "    hidden, bs = 64, 64\n",
        "    if strategy == 'uncertainty':\n",
        "        best_cfg = unc_results[dataset][method]['best_cfg']['train_config']\n",
        "        lr = best_cfg['learning_rate']\n",
        "        wd = best_cfg['weight_decay']\n",
        "    else:\n",
        "        best_cfg = sen_results[dataset]['best_cfg']['train_config']\n",
        "        lr = best_cfg['learning_rate']\n",
        "        wd = best_cfg['weight_decay']\n",
        "\n",
        "    # Get data splits\n",
        "    X_train_val, X_test, y_train_val, y_test = get_data_splits(dataset)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_val, dtype=torch.long)\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "    \n",
        "    train_config = TrainConfig(learning_rate=lr, weight_decay=wd, batch_size=bs, \n",
        "                                max_epochs=200, patience=20)\n",
        "    \n",
        "    # Create initial labeled pool\n",
        "    num_train = X_train_scaled.shape[0]\n",
        "    labeled_indices = torch.randperm(num_train)[:init]\n",
        "    unlabeled_indices = torch.tensor([i for i in range(num_train) if i not in labeled_indices.tolist()], dtype=torch.long)\n",
        "    \n",
        "    x_pool = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    y_pool = y_train_tensor.clone()\n",
        "    \n",
        "    # Active learning loop\n",
        "    while labeled_indices.numel() < min(budget, num_train):\n",
        "        # Train model on current labeled set\n",
        "        train_subset = TensorDataset(x_pool[labeled_indices], y_pool[labeled_indices])\n",
        "        \n",
        "        train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True)\n",
        "        \n",
        "        model = OneHiddenMLP(input_dim=X_train_scaled.shape[1], hidden_units=hidden, output_dim=len(np.unique(y_train_val)))\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        \n",
        "        train_passive(model, train_loader, test_loader, loss_fn, train_config)\n",
        "        \n",
        "        if unlabeled_indices.numel() == 0:\n",
        "            break\n",
        "        \n",
        "        # Query selection\n",
        "        if strategy == 'uncertainty':\n",
        "            sel = uncertainty_sampling(\n",
        "                model,\n",
        "                x_pool[unlabeled_indices].to('cpu'),\n",
        "                query,\n",
        "                UncertaintySamplingConfig(mode=\"classification\", method=method),\n",
        "            )\n",
        "        elif strategy == 'sensitivity':\n",
        "            sel = sensitivity_sampling(model, x_pool[unlabeled_indices].to('cpu'), query)\n",
        "        \n",
        "        # Update labeled and unlabeled sets\n",
        "        newly_selected = unlabeled_indices[sel]\n",
        "        labeled_indices = torch.unique(torch.cat([labeled_indices, newly_selected]))\n",
        "        mask = torch.ones_like(unlabeled_indices, dtype=torch.bool)\n",
        "        mask[sel] = False\n",
        "        unlabeled_indices = unlabeled_indices[mask]\n",
        "        \n",
        "        if labeled_indices.numel() >= budget:\n",
        "            break\n",
        "    \n",
        "    # Final evaluation on test set\n",
        "    final_train_subset = TensorDataset(x_pool[labeled_indices], y_pool[labeled_indices])\n",
        "    final_train_loader = DataLoader(final_train_subset, batch_size=bs, shuffle=True)\n",
        "    final_test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "    \n",
        "    final_model = OneHiddenMLP(input_dim=X_train_scaled.shape[1], hidden_units=hidden, output_dim=len(np.unique(y_train_val)))\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    \n",
        "    train_passive(final_model, final_train_loader, final_test_loader, loss_fn, train_config)\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    metrics = evaluate_classification(final_model, final_test_loader)\n",
        "    \n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running passive on iris...\n",
            "Running passive on wine...\n",
            "Running passive on breast_cancer...\n",
            "Running uncertainty on iris - entropy...\n",
            "Running uncertainty on iris - margin...\n",
            "Running uncertainty on iris - least_confidence...\n",
            "Running uncertainty on wine - entropy...\n",
            "Running uncertainty on wine - margin...\n",
            "Running uncertainty on wine - least_confidence...\n",
            "Running uncertainty on breast_cancer - entropy...\n",
            "Running uncertainty on breast_cancer - margin...\n",
            "Running uncertainty on breast_cancer - least_confidence...\n",
            "Running sensitivity on iris...\n",
            "Running sensitivity on wine...\n",
            "Running sensitivity on breast_cancer...\n"
          ]
        }
      ],
      "source": [
        "test_results = {\n",
        "    'passive': {},\n",
        "    'uncertainty': {},\n",
        "    'sensitivity': {}\n",
        "}\n",
        "\n",
        "for dataset in DATASETS:\n",
        "    print(f\"Running passive on {dataset}...\")\n",
        "    test_results['passive'][dataset] = evaluate_passive_test(dataset)\n",
        "\n",
        "# Evaluate uncertainty-based active learning on test set\n",
        "for dataset in DATASETS:\n",
        "    budget = ACTIVE_PARAMS[dataset]['budget']\n",
        "    test_results['uncertainty'][dataset] = {}\n",
        "    for method in UNCERTAINTY_METHODS:\n",
        "        print(f\"Running uncertainty on {dataset} - {method}...\")\n",
        "        test_results['uncertainty'][dataset][method] = {}\n",
        "        test_results['uncertainty'][dataset][method][str(budget)] = evaluate_active_test(dataset, 'uncertainty', method, budget)\n",
        "\n",
        "# Evaluate sensitivity-based active learning on test set\n",
        "for dataset in DATASETS:\n",
        "    budget = ACTIVE_PARAMS[dataset]['budget']\n",
        "    print(f\"Running sensitivity on {dataset}...\")\n",
        "    test_results['sensitivity'][dataset] = {}\n",
        "    test_results['sensitivity'][dataset][str(budget)] = evaluate_active_test(dataset, 'sensitivity', '', budget)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          dataset                        method  budget  accuracy      f1\n",
            "0            iris                       passive      80    0.9667  0.9666\n",
            "1            iris           uncertainty_entropy      80    0.9333  0.9333\n",
            "2            iris            uncertainty_margin      80    0.9667  0.9666\n",
            "3            iris  uncertainty_least_confidence      80    0.9333  0.9333\n",
            "4            iris                   sensitivity      80    0.9667  0.9666\n",
            "5            wine                       passive     100    0.9722  0.9710\n",
            "6            wine           uncertainty_entropy     100    0.9722  0.9710\n",
            "7            wine            uncertainty_margin     100    0.9722  0.9710\n",
            "8            wine  uncertainty_least_confidence     100    0.9722  0.9710\n",
            "9            wine                   sensitivity     100    0.9444  0.9407\n",
            "10  breast_cancer                       passive     200    0.9649  0.9623\n",
            "11  breast_cancer           uncertainty_entropy     200    0.9737  0.9719\n",
            "12  breast_cancer            uncertainty_margin     200    0.9737  0.9719\n",
            "13  breast_cancer  uncertainty_least_confidence     200    0.9474  0.9422\n",
            "14  breast_cancer                   sensitivity     200    0.9386  0.9349\n"
          ]
        }
      ],
      "source": [
        "summary_data = []\n",
        "\n",
        "for dataset in DATASETS:\n",
        "    budget = ACTIVE_PARAMS[dataset]['budget']\n",
        "    # Passive learning\n",
        "    summary_data.append({\n",
        "        'dataset': dataset,\n",
        "        'method': 'passive',\n",
        "        'budget': budget,\n",
        "        'accuracy': test_results['passive'][dataset]['accuracy'],\n",
        "        'f1': test_results['passive'][dataset]['f1_macro'],\n",
        "    })\n",
        "    \n",
        "    # Uncertainty methods\n",
        "    for method in UNCERTAINTY_METHODS:\n",
        "        max_budget = str(budget)\n",
        "        summary_data.append({\n",
        "            'dataset': dataset,\n",
        "            'method': f'uncertainty_{method}',\n",
        "            'budget': budget,\n",
        "            'accuracy': test_results['uncertainty'][dataset][method][max_budget]['accuracy'],\n",
        "            'f1': test_results['uncertainty'][dataset][method][max_budget]['f1_macro'],\n",
        "        })\n",
        "    \n",
        "    # Sensitivity method\n",
        "    max_budget = str(budget)\n",
        "    summary_data.append({\n",
        "        'dataset': dataset,\n",
        "        'method': 'sensitivity',\n",
        "        'budget': budget,\n",
        "        'accuracy': test_results['sensitivity'][dataset][max_budget]['accuracy'],\n",
        "        'f1': test_results['sensitivity'][dataset][max_budget]['f1_macro'],\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for nice display\n",
        "df = pd.DataFrame(summary_data)\n",
        "print(df.round(4))\n",
        "\n",
        "# Save summary\n",
        "df.to_csv(os.path.join(SAVE_DIR, 'cls_comparison_summary_test.csv'), index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Machine-Learning-441-fvr4FmDE",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
